{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nhstravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshapely\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m unary_union\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshapely\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeometry\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmultipolygon\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiPolygon\n\u001b[0;32m---> 15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnhstravel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloaders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlsoaloader\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlsoaloader\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfolium\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nhstravel'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "\n",
    "# from cartopy.geodesic import Geodesic\n",
    "from shapely.geometry.polygon import Point, Polygon\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "import nhstravel.loaders.lsoaloader as lsoaloader\n",
    "import folium\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the post code to lsoa look up sheet\n",
    "postcode_lookup = pd.read_csv(\n",
    "    \"../data/PCD_OA21_LSOA21_MSOA21_LAD_NOV22_UK_LU 3.csv\", encoding=\"ISO-8859-1\"\n",
    ")\n",
    "# postcode_lookup = pd.read_csv('/Users/paul.carroll/Github/pycom/nhs_time_of_travel/data/pcd_lsoa21cd_nov22_en.csv', encoding = \"ISO-8859-1\")\n",
    "postcode_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the hospital data set to get the postcodes for lookup\n",
    "# load in the hospital sites data to be used to score potential viable locations and filter for Cambridge\n",
    "\"\"\"\n",
    "hospitals = pd.read_csv('data/Hospital.csv')\n",
    "surrey_hospitals = hospitals.loc[hospitals['County'] == 'Surrey']\n",
    "surrey_hospitals\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target location post codes\n",
    "target_address1 = \"CB2 8AF\"  # 4 Trumpington Road\n",
    "target_address2 = \"CB2 0AY\"  # Nuffield Hospital (central cambridge location)\n",
    "list_of_target_addresses = [target_address1, target_address2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_coords = []\n",
    "for loc in list_of_target_addresses:\n",
    "    target_coords.append(ox.geocode(loc))\n",
    "\n",
    "\n",
    "target_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"annotating this cell to save where this is now\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lsoa 2021 code from the lookup file\n",
    "lsoa_codes = []\n",
    "lsoa_names = []\n",
    "\n",
    "for postcode in list_of_target_addresses:\n",
    "    lsoa_codes.append(\n",
    "        postcode_lookup.loc[postcode_lookup[\"pcds\"] == postcode][\"lsoa21cd\"].values[0]\n",
    "    )\n",
    "    lsoa_names.append(\n",
    "        postcode_lookup.loc[postcode_lookup[\"pcds\"] == postcode][\"ladnm\"].values[0]\n",
    "    )\n",
    "\n",
    "lsoa_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in lsoa data using the loaders function in nhs travel\n",
    "lsoa_with_population_pd1 = lsoaloader.build_lsoa_data_frame_for_area_england(\n",
    "    lsoa_names[0]\n",
    ")\n",
    "# lsoa_with_population_pd1 = lsoaloader.build_lsoa_data_frame_for_area_england(lsoa_codes[0])#\n",
    "\n",
    "remapped_lsoa1 = lsoaloader.load_geo_json_shapefiles_for_lsoas(\n",
    "    lsoa_with_population_pd1, lsoa_names[0]\n",
    ")\n",
    "# remapped_lsoa1 = lsoaloader.load_geo_json_shapefiles_for_lsoas(lsoa_with_population_pd1, lsoa_codes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapped_lsoa1.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_coords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_coords1 = target_coords[0]\n",
    "\n",
    "# gd = Geodesic()\n",
    "# bounding_poly1 = Polygon(gd.circle(lon=target_coords1[1], lat=target_coords1[0], radius=500))\n",
    "\n",
    "\n",
    "target_point1 = Point(target_coords1[1], target_coords1[0])\n",
    "\n",
    "neighboring_polys1 = {\"lsoa_codes\": [], \"population\": [], \"polygons\": []}\n",
    "for lsoa in remapped_lsoa1[\"features\"]:\n",
    "    lsoa_polygon = shape(lsoa[\"geometry\"])\n",
    "    if (\n",
    "        lsoa_polygon.contains(target_point1)\n",
    "        or lsoa_polygon.distance(target_point1) < 500\n",
    "    ):\n",
    "        neighboring_polys1[\"lsoa_codes\"].append(lsoa[\"properties\"][\"LSOA21CD\"])\n",
    "        neighboring_polys1[\"population\"].append(lsoa[\"properties\"][\"all ages\"])\n",
    "        neighboring_polys1[\"polygons\"].append(lsoa_polygon)\n",
    "\n",
    "    \"\"\"if lsoa_polygon.contains(target_point1) or bounding_poly1.intersects(lsoa_polygon):\n",
    "        neighboring_polys1['lsoa_codes'].append(lsoa['properties']['LSOA21CD'])\n",
    "        neighboring_polys1['population'].append(lsoa['properties']['all ages'])\n",
    "        neighboring_polys1['polygons'].append(lsoa_polygon)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neighboring_polys1[\"lsoa_codes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remapped_lsoa1[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in lsoa data using the loaders function in nhs travel\n",
    "lsoa_with_population_pd2 = lsoaloader.build_lsoa_data_frame_for_area_england(\n",
    "    lsoa_names[1]\n",
    ")\n",
    "remapped_lsoa2 = lsoaloader.load_geo_json_shapefiles_for_lsoas(\n",
    "    lsoa_with_population_pd2, lsoa_names[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_coords2 = target_coords[1]\n",
    "\n",
    "# gd = Geodesic()\n",
    "# bounding_poly2 = Polygon(gd.circle(lon=target_coords2[1], lat=target_coords2[0], radius=500))\n",
    "\n",
    "target_point2 = Point(target_coords2[1], target_coords2[0])\n",
    "\n",
    "neighboring_polys2 = {\"lsoa_codes\": [], \"population\": [], \"polygons\": []}\n",
    "for lsoa in remapped_lsoa2[\"features\"]:\n",
    "    lsoa_polygon = shape(lsoa[\"geometry\"])\n",
    "    if (\n",
    "        lsoa_polygon.contains(target_point2)\n",
    "        or lsoa_polygon.distance(target_point2) < 500\n",
    "    ):\n",
    "        neighboring_polys2[\"lsoa_codes\"].append(lsoa[\"properties\"][\"LSOA21CD\"])\n",
    "        neighboring_polys2[\"population\"].append(lsoa[\"properties\"][\"all ages\"])\n",
    "        neighboring_polys2[\"polygons\"].append(lsoa_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighboring_polys_merged = (\n",
    "    neighboring_polys1[\"polygons\"] + neighboring_polys2[\"polygons\"]\n",
    ")\n",
    "neighboring_multipoly = MultiPolygon(neighboring_polys_merged)\n",
    "hull = neighboring_multipoly.convex_hull\n",
    "hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull_neighboring_polys = {\"lsoa_codes\": [], \"population\": [], \"polygons\": []}\n",
    "for lsoa in remapped_lsoa1[\"features\"]:\n",
    "    lsoa_polygon = shape(lsoa[\"geometry\"])\n",
    "    if hull.intersects(lsoa_polygon):\n",
    "        hull_neighboring_polys[\"lsoa_codes\"].append(lsoa[\"properties\"][\"LSOA21CD\"])\n",
    "        hull_neighboring_polys[\"population\"].append(lsoa[\"properties\"][\"all ages\"])\n",
    "        hull_neighboring_polys[\"polygons\"].append(lsoa_polygon)\n",
    "hull_neighboring_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hull_neighboring_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighboring_polys_merged = hull_neighboring_polys[\"polygons\"]\n",
    "bounding_poly_merged = unary_union(neighboring_polys_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_poly_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.graph_from_polygon(bounding_poly_merged)\n",
    "# ---------------------------------------------------------------------------------------\n",
    "ox.plot_graph(G, figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = ox.graph_to_gdfs(G)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the addresses to lat long coordinates and get the nearest node on the graph\n",
    "target_coords1 = ox.geocode(target_address1)\n",
    "\n",
    "target_node1 = ox.distance.nearest_nodes(G, target_coords1[1], target_coords1[0])\n",
    "\n",
    "target_coords2 = ox.geocode(target_address2)\n",
    "target_node2 = ox.distance.nearest_nodes(G, target_coords2[1], target_coords1[0])\n",
    "\n",
    "list_of_target_nodes = [target_node1, target_node2]\n",
    "list_of_target_coords = [target_coords1, target_coords2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_sample1 = pd.DataFrame(columns = nodes.columns)\n",
    "nodes_sample1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe of nodes that are in the neighboring polys and get the sample nodes with the corresponding population and lsoa codes\n",
    "nodes_sample1 = pd.DataFrame(columns=nodes.columns)\n",
    "list_of_lsoa_codes = []\n",
    "list_of_pops = []\n",
    "\n",
    "for j in range(nodes.shape[0]):\n",
    "    for i in range(len(neighboring_polys1[\"polygons\"])):\n",
    "        lsoa = neighboring_polys1[\"polygons\"][i]\n",
    "\n",
    "        if lsoa.contains(nodes.iloc[j][\"geometry\"]):\n",
    "            nodes_sample1 = nodes_sample1.append(nodes.iloc[j])\n",
    "            list_of_lsoa_codes.append(neighboring_polys1[\"lsoa_codes\"][i])\n",
    "            list_of_pops.append(neighboring_polys1[\"population\"][i])\n",
    "            continue\n",
    "\n",
    "nodes_sample1[\"lsoa_codes\"] = list_of_lsoa_codes\n",
    "nodes_sample1[\"lsoa_population\"] = list_of_pops\n",
    "\n",
    "nodes_sample1 = nodes_sample1.drop(target_node1)\n",
    "\n",
    "nodes_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe of nodes that are in the neighboring polys and get the sample nodes with the corresponding population and lsoa codes\n",
    "nodes_sample1 = pd.DataFrame(columns=nodes.columns)\n",
    "list_of_lsoa_codes = []\n",
    "list_of_pops = []\n",
    "\n",
    "\n",
    "for i in range(len(neighboring_polys1[\"polygons\"])):\n",
    "    lsoa = neighboring_polys1[\"polygons\"][i]\n",
    "    for j in range(nodes.shape[0]):\n",
    "        if lsoa.contains(nodes.iloc[j][\"geometry\"]):\n",
    "            nodes_sample1 = nodes_sample1.append(nodes.iloc[j])\n",
    "            list_of_lsoa_codes.append(neighboring_polys1[\"lsoa_codes\"][i])\n",
    "            list_of_pops.append(neighboring_polys1[\"population\"][i])\n",
    "\n",
    "nodes_sample1[\"lsoa_codes\"] = list_of_lsoa_codes\n",
    "nodes_sample1[\"lsoa_population\"] = list_of_pops\n",
    "\n",
    "nodes_sample1 = nodes_sample1.drop(target_node1)\n",
    "\n",
    "nodes_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe of nodes that are in the neighboring polys and get the sample nodes with the corresponding population and lsoa codes\n",
    "nodes_sample2 = pd.DataFrame(columns=nodes.columns)\n",
    "list_of_lsoa_codes = []\n",
    "list_of_pops = []\n",
    "\n",
    "\n",
    "for i in range(len(neighboring_polys2[\"polygons\"])):\n",
    "    lsoa = neighboring_polys2[\"polygons\"][i]\n",
    "    for j in range(nodes.shape[0]):\n",
    "        if lsoa.contains(nodes.iloc[j][\"geometry\"]):\n",
    "            nodes_sample2 = nodes_sample2.append(nodes.iloc[j])\n",
    "            list_of_lsoa_codes.append(neighboring_polys2[\"lsoa_codes\"][i])\n",
    "            list_of_pops.append(neighboring_polys2[\"population\"][i])\n",
    "\n",
    "nodes_sample2[\"lsoa_codes\"] = list_of_lsoa_codes\n",
    "nodes_sample2[\"lsoa_population\"] = list_of_pops\n",
    "\n",
    "nodes_sample2 = nodes_sample2.drop(target_node2)\n",
    "\n",
    "nodes_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_sample = nodes_sample2\n",
    "node = 554267\n",
    "current_lsoa = nodes_sample[\"lsoa_codes\"][node]\n",
    "nodes_in_lsoa = nodes_sample.loc[nodes_sample[\"lsoa_codes\"] == current_lsoa].shape[0]\n",
    "nodes_in_lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe of nodes that are in the neighboring polys and get the sample nodes with the corresponding population and lsoa codes\n",
    "nodes_sample1 = pd.DataFrame(columns=nodes.columns)\n",
    "nodes_sample2 = pd.DataFrame(columns=nodes.columns)\n",
    "\n",
    "list_of_lsoa_codes1 = []\n",
    "list_of_pops1 = []\n",
    "\n",
    "list_of_lsoa_codes2 = []\n",
    "list_of_pops2 = []\n",
    "\n",
    "for lsoa in neighboring_polys_merged:\n",
    "    for i in range(nodes.shape[0]):\n",
    "        if lsoa.contains(nodes.iloc[i][\"geometry\"]):\n",
    "            if lsoa in neighboring_polys1[\"polygons\"]:\n",
    "                index = neighboring_polys1[\"polygons\"].index(lsoa)\n",
    "                list_of_lsoa_codes1.append(neighboring_polys1[\"lsoa_codes\"][index])\n",
    "                list_of_pops1.append(neighboring_polys1[\"population\"][index])\n",
    "                nodes_sample1 = nodes_sample1.append(nodes.iloc[i])\n",
    "            elif lsoa in neighboring_polys2[\"polygons\"]:\n",
    "                index = neighboring_polys2[\"polygons\"].index(lsoa)\n",
    "                list_of_lsoa_codes2.append(neighboring_polys2[\"lsoa_codes\"][index])\n",
    "                list_of_pops2.append(neighboring_polys2[\"population\"][index])\n",
    "                nodes_sample2 = nodes_sample2.append(nodes.iloc[i])\n",
    "\n",
    "\n",
    "nodes_sample1[\"lsoa_codes\"] = list_of_lsoa_codes1\n",
    "nodes_sample1[\"lsoa_population\"] = list_of_pops1\n",
    "\n",
    "# nodes_sample1 = nodes_sample1.drop(target_node1)\n",
    "\n",
    "\n",
    "nodes_sample2[\"lsoa_codes\"] = list_of_lsoa_codes2\n",
    "nodes_sample2[\"lsoa_population\"] = list_of_pops2\n",
    "\n",
    "nodes_sample2 = nodes_sample2.drop(target_node2)\n",
    "\n",
    "\n",
    "nodes_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to calculate a score from a list of lengths calculated from the target node to each of the 100 sample nodes\n",
    "def create_score(list_of_lengths, list_of_multipliers):\n",
    "    score = 1000\n",
    "    for l, m in zip(list_of_lengths, list_of_multipliers):\n",
    "        deduction = (\n",
    "            (((l / 1000) / 4.5) * 60) * m * 5\n",
    "        )  # get the length in km divide by speed 4.5 km/h then divide by 60 to get time in minutes\n",
    "        score = (\n",
    "            score - deduction\n",
    "        )  # decrement the score by the derivation of time taken to each of the 100 nodes\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate multiple shortest route lengths from the target node to each of the 100 sample nodes\n",
    "def create_list_of_lengths(nodes_sample, target_node):\n",
    "    list_of_lengths = []\n",
    "    list_of_multipliers = []\n",
    "\n",
    "    for node in nodes_sample.index:\n",
    "        current_lsoa = nodes_sample[\"lsoa_codes\"][node]\n",
    "        nodes_in_lsoa = nodes_sample.loc[\n",
    "            nodes_sample[\"lsoa_codes\"] == current_lsoa\n",
    "        ].shape[0]\n",
    "        total_pop = nodes_sample[\"lsoa_population\"].unique().sum()\n",
    "        node_pop = nodes_sample[\"lsoa_population\"][node] / nodes_in_lsoa\n",
    "        multiplier = 1 - (node_pop / total_pop)\n",
    "        try:\n",
    "            length = nx.shortest_path_length(\n",
    "                G, source=node, target=target_node, weight=\"length\"\n",
    "            )  # calculate route from target node to sample node\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        list_of_lengths.append(length)  # append the length to the list\n",
    "        list_of_multipliers.append(\n",
    "            multiplier\n",
    "        )  # append the multipliers to the list for score creation\n",
    "\n",
    "    return [list_of_lengths, list_of_multipliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function defined above to generate a list of lengths between the target nodes and sample nodes\n",
    "# then generate the score for each and store them in a dictionary\n",
    "target_scores = {}\n",
    "target1_lengths = create_list_of_lengths(nodes_sample1, list_of_target_nodes[0])\n",
    "target2_lengths = create_list_of_lengths(nodes_sample2, list_of_target_nodes[1])\n",
    "target_scores[\"Site 1\"] = create_score(target1_lengths[0], target1_lengths[1])\n",
    "target_scores[\"Site 2\"] = create_score(target2_lengths[0], target2_lengths[1])\n",
    "target_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the scores for each proposed target site\n",
    "print(\"The score for Site 1: {} is {}\".format(target_address1, target_scores[\"Site 1\"]))\n",
    "print(\"The score for Site 2: {} is {}\".format(target_address2, target_scores[\"Site 2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate dictionary to store routes for all 100 nodes for each proposed site\n",
    "target_to_nodes_routes = {}\n",
    "target_node_names = [\"Site1\", \"Site2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_samples = [nodes_sample, nodes_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate multiple shortest routes for each site and store in dictionary for plotting\n",
    "for site, target_node in zip(target_node_names, list_of_target_nodes):\n",
    "    list_of_routes = []\n",
    "    for node in nodes_sample.index:\n",
    "        try:\n",
    "            route = nx.shortest_path(G, source=node, target=target_node, weight='length') #calculate route from target node to sample node\n",
    "        except Exception as el\n",
    "        list_of_routes.append(route) #append the length to the list\n",
    "    target_to_nodes_routes[site] = list_of_routes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the routes from Site 1 to all 100 sample nodes\n",
    "fig, ax = ox.plot_graph_routes(\n",
    "    G, target_to_nodes_routes[\"Site1\"], route_linewidth=6, bgcolor=\"k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the routes from Site 1 to all 100 sample nodes\n",
    "fig, ax = ox.plot_graph_routes(\n",
    "    G, target_to_nodes_routes[\"Site2\"], route_linewidth=6, bgcolor=\"k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac5d808bfc8f44bf6ad6509a5eb0136ce886e67e9c9137a39033c0357f68118b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
